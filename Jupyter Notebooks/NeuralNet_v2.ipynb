{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from collections import Counter\n",
    "import time\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "#from keras.utils import to_categorical\n",
    "import feather\n",
    "import random\n",
    "from datetime import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = \"Datasets/final_datasets/merged_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = feather.read_dataframe(f\"{FILENAME}.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove those one-hot encoded columns in the dataset created by Abhi\n",
    "\n",
    "def in_name(c, one_hots):\n",
    "    for col_name in one_hots:\n",
    "        if c.startswith(f\"{col_name}_\"):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "one_hots = ['Wind_Direction', 'Timezone','State', 'Weather_Condition']\n",
    "remove = [col for col in data.columns if in_name(col, one_hots)]\n",
    "df = data.drop(remove, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2922400\n"
     ]
    }
   ],
   "source": [
    "# Remove missing values\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Severity'] = df['Severity'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean wind direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* \"CALM\" = [\"Calm\", \"CALM\"]\n",
    "* \"W\" = [\"W\", \"West\", \"WSW\", \"WNW\"] \n",
    "* \"S\" = [\"S\", \"South\", \"SSW\", \"SSE\"] \n",
    "* \"N\" = [\"N\", \"North\", \"NNW\", \"NNE\"] \n",
    "* \"E\" = [\"E\", \"East\", \"ESE\", \"ENE\"]\n",
    "* \"VAR\" = [\"VAR\", \"Variable\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wind Direction after simplification:  ['SW' 'S' 'W' 'NW' 'N' 'VAR' 'SE' 'E' 'NE' 'CALM']\n"
     ]
    }
   ],
   "source": [
    "df.loc[df['Wind_Direction']=='Calm','Wind_Direction'] = 'CALM'\n",
    "df.loc[(df['Wind_Direction']=='West')|(df['Wind_Direction']=='WSW')|(df['Wind_Direction']=='WNW'),'Wind_Direction'] = 'W'\n",
    "df.loc[(df['Wind_Direction']=='South')|(df['Wind_Direction']=='SSW')|(df['Wind_Direction']=='SSE'),'Wind_Direction'] = 'S'\n",
    "df.loc[(df['Wind_Direction']=='North')|(df['Wind_Direction']=='NNW')|(df['Wind_Direction']=='NNE'),'Wind_Direction'] = 'N'\n",
    "df.loc[(df['Wind_Direction']=='East')|(df['Wind_Direction']=='ESE')|(df['Wind_Direction']=='ENE'),'Wind_Direction'] = 'E'\n",
    "df.loc[df['Wind_Direction']=='Variable','Wind_Direction'] = 'VAR'\n",
    "print(\"Wind Direction after simplification: \", df['Wind_Direction'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean weather condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Counter(df['Weather_Condition'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.timeanddate.com/weather/glossary.html <br>\n",
    "\n",
    "**Create features according the different weather conditions** <br>\n",
    "Scattered clouds, partly cloudy = PARTLY CLOUDY <br>\n",
    "Overcast, Mostly cloudly, Cloudy = CLOUDY <br>\n",
    "Fair, Clear = CLEAR <br>\n",
    "Snow (light snow, heavy snow), and wintry mix  = SNOW <br>\n",
    "drizzle, light rain/drizzle, light freezing rain/drizzle = LIGHT RAIN <br>\n",
    "Heavy Rain, heavy thunderstorms, heavy t-storm = HEAVY RAIN <br>\n",
    "Haze, fog, mist, smoke = fog     *(see https://www.worldatlas.com/articles/what-are-the-differences-between-mist-haze-and-fog.html)*<br>\n",
    "Rain, light thunderstorms, thunderstorms, t-storm, thunder = RAIN <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_condition(string):\n",
    "    \n",
    "    conditions = ['Clear', 'Partly Cloudy', 'Cloudy', 'Snow', 'Light Rain', 'Heavy Rain', 'Rain', 'Fog'] \n",
    "    strings = [['clear', 'fair'],\n",
    "              ['partly cloudy', 'scattered clouds'],\n",
    "              ['overcast', 'mostly cloudy', 'cloudy'],\n",
    "              ['snow', 'wintry mix'],\n",
    "              ['drizzle', 'light rain', 'light freezing rain'],\n",
    "              ['heavy rain', 'heavy thunderstorms', 'heavy t-storm'],\n",
    "              ['rain', 'thunderstorms', 't-storm', 'thunder', 'showers'],\n",
    "              ['fog', 'haze', 'mist', 'smoke']]\n",
    "\n",
    "    for j, k in enumerate(strings):\n",
    "        for val in k:\n",
    "            if val in string.lower():\n",
    "                return conditions[j]\n",
    "    return 'Others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in df['Weather_Condition'].values:\n",
    "    res.append(get_condition(i))\n",
    "\n",
    "df['Condition'] = res\n",
    "df[['Condition', 'Weather_Condition']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "conditions = ['Clear', 'Partly Cloudy', 'Cloudy', 'Snow', 'Light Rain', 'Heavy Rain', 'Rain', 'Fog', 'Others'] \n",
    "\n",
    "for i in conditions:\n",
    "    print(i, \":\")\n",
    "    print(set(df[df['Condition']==i]['Weather_Condition']))\n",
    "    print(sum(df['Condition']==i))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "df = df[df['Condition']!='Others']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode ['Wind_Direction', 'Timezone', 'State', 'Condition']\n",
    "\n",
    "one_hots = ['Wind_Direction', 'Timezone','State', 'Condition']\n",
    "oh = pd.DataFrame()\n",
    "for c in one_hots:\n",
    "    dummies = pd.get_dummies(df[c], prefix=c)\n",
    "    oh = pd.concat([oh, dummies], axis=1)\n",
    "\n",
    "df = pd.concat([df, oh], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this dataframe\n",
    "df = df.reset_index(drop = True)\n",
    "df.to_feather(\"{}_v1.feather\".format(FILENAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = feather.read_dataframe(\"{}_v1.feather\".format(FILENAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With numeric attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data\n",
    "#BUM NOEXIT ROUNABOUT GIVEWAY removed due to badly distributed data\n",
    "drop = ['Unnamed: 0', 'ID', 'Start_Lat', 'Start_Lng', 'Start_Time', 'End_Time', 'Weather_Timestamp', 'Description', \n",
    "        'Distance(mi)', \n",
    "        'County', 'City', 'Airport_Code', \n",
    "        'Wind_Direction', 'Timezone', 'State', 'Condition', 'Weather_Condition',\n",
    "        'Street', 'Bump', 'No_Exit', 'Roundabout', 'Give_Way', 'Traffic_Calming',\n",
    "        \"Wind_Direction\"]\n",
    "\n",
    "df = df.drop(drop, axis=1).reset_index(drop=True)\n",
    "\n",
    "# Convert to feather file format\n",
    "df.to_feather(\"{}_numeric_v2.feather\".format(FILENAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### without numeric attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filter the data\n",
    "#BUM NOEXIT ROUNABOUT GIVEWAY removed due to badly distributed data\n",
    "drop = ['Unnamed: 0', 'ID', 'Start_Lat', 'Start_Lng', 'Start_Time', 'End_Time', 'Weather_Timestamp', 'Description', \n",
    "        'Distance(mi)', \n",
    "        'County', 'City', 'Airport_Code', \n",
    "        'Wind_Direction', 'Timezone', 'State', 'Condition', 'Weather_Condition',\n",
    "        'Street', 'Bump', 'No_Exit', 'Roundabout', 'Give_Way', 'Traffic_Calming',\n",
    "       'Temperature(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Direction', 'Wind_Speed(mph)', 'Precipitation(in)',\n",
    "       'Population_County', 'Drive_County', 'Transit_County', 'Walk_County', 'MedianHouseholdIncome_County']\n",
    "\n",
    "df = df.drop(drop, axis=1).reset_index(drop=True)\n",
    "\n",
    "# Convert to feather file format\n",
    "df.to_feather(\"{}_v2.feather\".format(FILENAME))\n",
    "\n",
    "# clears memory allocated to df\n",
    "df = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear memory\n",
    "del(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding best neuron size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = feather.read_dataframe(\"{}_v2.feather\".format(FILENAME))\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# One hot encode labels\n",
    "n = len(data)\n",
    "labels = data['Severity']\n",
    "y = np.zeros((n, 4))\n",
    "for i in range(n):\n",
    "    y[i, labels[i]-1] = 1\n",
    "    \n",
    "X = data.drop('Severity', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30034)\n",
    "\n",
    "max_neurons = X_train.shape[1]\n",
    "neuron_size = range(max_neurons,4,-10)\n",
    "\n",
    "for i in neuron_size:\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(i, activation=tf.nn.swish,input_shape=(X_train.shape[1],)))\n",
    "    model.add(tf.keras.layers.Dense(4, activation=tf.nn.sigmoid))\n",
    "\n",
    "    # Compile and print out summary of model\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    print(\"==================================================\")\n",
    "    print(\"Number of Neurons: \",i)\n",
    "    print(\"==================================================\")\n",
    "    model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "    model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation with numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "data = feather.read_dataframe(\"{}_numeric_v2.feather\".format(FILENAME))\n",
    "labels = data['Severity']\n",
    "X = data.drop('Severity', axis=1)\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, random_state=30034, shuffle=False)\n",
    "\n",
    "fold_no = 1\n",
    "accs = []  # store each accuracy\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X, labels):\n",
    "\n",
    "    # One hot encode labels\n",
    "    print(\"FOLD NUMBER = \", str(fold_no))\n",
    "\n",
    "\n",
    "    X_train = X[train_index]\n",
    "    X_test = X[test_index]\n",
    "    \n",
    "    \n",
    "    y_train = np.zeros((len(X_train), 4))\n",
    "    for i in range(len(X_train)):\n",
    "        y_train[i, labels[i]-1] = 1\n",
    "\n",
    "    y_test = np.zeros((len(X_test), 4))\n",
    "    for i in range(len(X_test)):\n",
    "        y_test[i, labels[i]-1] = 1\n",
    "\n",
    "    EPOCHS = 5\n",
    "    BATCH_SIZE = 128\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(70, activation=tf.nn.swish,input_shape=(X_train.shape[1],)))\n",
    "    model.add(tf.keras.layers.Dense(4, activation=tf.nn.sigmoid))\n",
    "\n",
    "    # Compile and print out summary of model\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "    (test_loss, test_acc) = model.evaluate(X_test, y_test)\n",
    "    print('Accuracy:', test_acc)\n",
    "    accs.append(test_acc)\n",
    "    print(\"============================================\")\n",
    "    fold_no+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation without numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "p = []\n",
    "t = []\n",
    "for i in y_preds:\n",
    "    p.append(np.argmax(i)+1)\n",
    "\n",
    "for i in y_test:\n",
    "    t.append(np.argmax(i)+1)    \n",
    "\n",
    "print(\"accuracy:\", accuracy_score(t, p))\n",
    "\n",
    "cm=confusion_matrix(t,p)\n",
    "cm = pd.DataFrame(cm, index = [i for i in \"1234\"],\n",
    "                  columns = [i for i in \"1234\"])\n",
    "cm.index.name = 'Actual'\n",
    "cm.columns.name = 'Predicted'\n",
    "sns.heatmap(cm, annot=True, \n",
    "            cmap='Blues', cbar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "data = feather.read_dataframe(\"{}_v2.feather\".format(FILENAME))\n",
    "labels = data['Severity']\n",
    "X = data.drop('Severity', axis=1)\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, random_state=30034, shuffle=False)\n",
    "\n",
    "fold_no = 1\n",
    "accs = []  # store each accuracy\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X, labels):\n",
    "\n",
    "    # One hot encode labels\n",
    "    print(\"FOLD NUMBER = \", str(fold_no))\n",
    "\n",
    "\n",
    "    X_train = X[train_index]\n",
    "    X_test = X[test_index]\n",
    "\n",
    "    y_train = np.zeros((len(X_train), 4))\n",
    "    for i in range(len(X_train)):\n",
    "        y_train[i, labels[i]-1] = 1\n",
    "\n",
    "    y_test = np.zeros((len(X_test), 4))\n",
    "    for i in range(len(X_test)):\n",
    "        y_test[i, labels[i]-1] = 1\n",
    "\n",
    "    EPOCHS = 5\n",
    "    BATCH_SIZE = 128\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(70, activation=tf.nn.swish,input_shape=(X_train.shape[1],)))\n",
    "    model.add(tf.keras.layers.Dense(4, activation=tf.nn.sigmoid))\n",
    "\n",
    "    # Compile and print out summary of model\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "    (test_loss, test_acc) = model.evaluate(X_test, y_test)\n",
    "    print('Accuracy:', test_acc)\n",
    "    accs.append(test_acc)\n",
    "    print(\"============================================\")\n",
    "    fold_no+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_sev = []\n",
    "for i in data[\"Severity\"].values:\n",
    "    if i == 1 or i == 2:\n",
    "        grouped_sev.append(0)\n",
    "    else:\n",
    "        grouped_sev.append(1)\n",
    "\n",
    "data[\"Grouped_Severity\"] = grouped_sev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "labels = data['Grouped_Severity']\n",
    "X = data.drop(['Severity',\"Grouped_Severity\"], axis=1)\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, random_state=30034, shuffle=False)\n",
    "\n",
    "fold_no = 1\n",
    "accs = []  # store each accuracy\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X, labels):\n",
    "\n",
    "    # One hot encode labels\n",
    "    print(\"FOLD NUMBER = \", str(fold_no))\n",
    "\n",
    "\n",
    "    X_train = X[train_index]\n",
    "    X_test = X[test_index]\n",
    "\n",
    "    y_train = labels[train_index]\n",
    "    y_test = labels[test_index]\n",
    "\n",
    "    EPOCHS = 10\n",
    "    BATCH_SIZE = 128\n",
    "\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(40, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "    (test_loss, test_acc) = model.evaluate(X_test, y_test)\n",
    "    print('Accuracy:', test_acc)\n",
    "    accs.append(test_acc)\n",
    "    print(\"============================================\")\n",
    "    fold_no+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = feather.read_dataframe(\"{}_numeric_v2.feather\".format(FILENAME))\n",
    "\n",
    "grouped_sev = []\n",
    "for i in data[\"Severity\"].values:\n",
    "    if i == 1 or i == 2:\n",
    "        grouped_sev.append(0)\n",
    "    else:\n",
    "        grouped_sev.append(1)\n",
    "\n",
    "data[\"Grouped_Severity\"] = grouped_sev\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "labels = data['Grouped_Severity']\n",
    "X = data.drop(['Severity',\"Grouped_Severity\"], axis=1)\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, random_state=30034, shuffle=False)\n",
    "\n",
    "fold_no = 1\n",
    "accs = []  # store each accuracy\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X, labels):\n",
    "\n",
    "    # One hot encode labels\n",
    "    print(\"FOLD NUMBER = \", str(fold_no))\n",
    "\n",
    "\n",
    "    X_train = X[train_index]\n",
    "    X_test = X[test_index]\n",
    "\n",
    "    y_train = labels[train_index]\n",
    "    y_test = labels[test_index]\n",
    "\n",
    "    EPOCHS = 10\n",
    "    BATCH_SIZE = 128\n",
    "\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(40, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "    (test_loss, test_acc) = model.evaluate(X_test, y_test)\n",
    "    print('Accuracy:', test_acc)\n",
    "    accs.append(test_acc)\n",
    "    print(\"============================================\")\n",
    "    fold_no+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Temperature(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', \n",
    "        'Wind_Speed(mph)', 'Precipitation(in)',\n",
    "       'Population_County', 'Drive_County', 'Transit_County', 'Walk_County', 'MedianHouseholdIncome_County']\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "f, axes = plt.subplots(6,2, figsize=(15,20))\n",
    "y = 0;\n",
    "for name in cols[1:]:\n",
    "    i, j = divmod(y, 2)\n",
    "    sns.boxplot(x=data[name], ax=axes[i, j])\n",
    "    y = y+1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing  outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def outlier_removal(data,columns):\n",
    "    for col in columns:\n",
    "        Q1 = np.quantile(data[col].values,0.25)\n",
    "        Q3 = np.quantile(data[col].values,0.75)\n",
    "        IQR = Q3-Q1\n",
    "        \n",
    "        lower = Q1 - 1.5*IQR\n",
    "        upper = Q3+ 1.5*IQR\n",
    "        \n",
    "        data = data[(data[col]>=lower) & (data[col]<=upper)]\n",
    "    return data\n",
    "\n",
    "\n",
    "data = feather.read_dataframe(\"{}_numeric_v2.feather\".format(FILENAME))\n",
    "\n",
    "numeric_cols = ['Temperature(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', \n",
    "        'Wind_Speed(mph)', 'Precipitation(in)',\n",
    "       'Population_County', 'Drive_County', 'Transit_County', 'Walk_County', 'MedianHouseholdIncome_County']\n",
    "data = outlier_removal(data,numeric_cols).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = ['Temperature(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', \n",
    "        'Wind_Speed(mph)', 'Precipitation(in)',\n",
    "       'Population_County', 'Drive_County', 'Transit_County', 'Walk_County', 'MedianHouseholdIncome_County']\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "f, axes = plt.subplots(6,2, figsize=(15,20))\n",
    "y = 0;\n",
    "for name in cols[1:]:\n",
    "    i, j = divmod(y, 2)\n",
    "    sns.boxplot(x=new_data[name], ax=axes[i, j])\n",
    "    y = y+1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD NUMBER =  1\n",
      "Epoch 1/20\n",
      "850661/850661 [==============================] - 7s 8us/sample - loss: 0.4989 - acc: 0.7365\n",
      "Epoch 2/20\n",
      "850661/850661 [==============================] - 7s 8us/sample - loss: 0.4838 - acc: 0.7494\n",
      "Epoch 3/20\n",
      "850661/850661 [==============================] - 7s 8us/sample - loss: 0.4788 - acc: 0.7529\n",
      "Epoch 4/20\n",
      "850661/850661 [==============================] - 7s 9us/sample - loss: 0.4756 - acc: 0.7552\n",
      "Epoch 5/20\n",
      "850661/850661 [==============================] - 7s 8us/sample - loss: 0.4732 - acc: 0.7570\n",
      "Epoch 6/20\n",
      "850661/850661 [==============================] - 7s 9us/sample - loss: 0.4716 - acc: 0.7580\n",
      "Epoch 7/20\n",
      "850661/850661 [==============================] - 7s 8us/sample - loss: 0.4703 - acc: 0.7588\n",
      "Epoch 8/20\n",
      "850661/850661 [==============================] - 7s 8us/sample - loss: 0.4693 - acc: 0.7594\n",
      "Epoch 9/20\n",
      "850661/850661 [==============================] - 7s 8us/sample - loss: 0.4685 - acc: 0.7602\n",
      "Epoch 10/20\n",
      "850661/850661 [==============================] - 7s 8us/sample - loss: 0.4677 - acc: 0.7607\n",
      "Epoch 11/20\n",
      "850661/850661 [==============================] - 7s 9us/sample - loss: 0.4670 - acc: 0.7612\n",
      "Epoch 12/20\n",
      "850661/850661 [==============================] - 7s 9us/sample - loss: 0.4664 - acc: 0.7614\n",
      "Epoch 13/20\n",
      "850661/850661 [==============================] - 7s 8us/sample - loss: 0.4659 - acc: 0.7619\n",
      "Epoch 14/20\n",
      "850661/850661 [==============================] - 7s 9us/sample - loss: 0.4654 - acc: 0.7624\n",
      "Epoch 15/20\n",
      "850661/850661 [==============================] - 7s 9us/sample - loss: 0.4648 - acc: 0.7626\n",
      "Epoch 16/20\n",
      "850661/850661 [==============================] - 7s 9us/sample - loss: 0.4644 - acc: 0.7630\n",
      "Epoch 17/20\n",
      "850661/850661 [==============================] - 7s 8us/sample - loss: 0.4640 - acc: 0.7632\n",
      "Epoch 18/20\n",
      "850661/850661 [==============================] - 7s 8us/sample - loss: 0.4635 - acc: 0.7634\n",
      "Epoch 19/20\n",
      "850661/850661 [==============================] - 7s 8us/sample - loss: 0.4630 - acc: 0.7638\n",
      "Epoch 20/20\n",
      "850661/850661 [==============================] - 7s 8us/sample - loss: 0.4626 - acc: 0.7641\n",
      "425331/425331 [==============================] - 6s 13us/sample - loss: 0.4819 - acc: 0.7494\n",
      "Accuracy: 0.7493975\n",
      "accuracy: 0.7493975280428654\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "FOLD NUMBER =  2\n",
      "Epoch 1/20\n",
      "166656/850661 [====>.........................] - ETA: 6s - loss: 0.5310 - acc: 0.7232"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-2211b1496ec9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data['Grouped_Severity'] = np.where(data['Severity']<=2, 0, 1)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.feature_selection.chi2\n",
    "\n",
    "labels = data['Grouped_Severity']\n",
    "#dropping percipitation and visibility due to all values removed as outliers\n",
    "X = data.drop(['Severity',\"Grouped_Severity\",'Precipitation(in)','Visibility(mi)'], axis=1)\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, random_state=30034, shuffle=False)\n",
    "\n",
    "fold_no = 1\n",
    "accs = []  # store each accuracy\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X, labels):\n",
    "\n",
    "    # One hot encode labels\n",
    "    print(\"FOLD NUMBER = \", str(fold_no))\n",
    "\n",
    "\n",
    "    X_train = X[train_index]\n",
    "    X_test = X[test_index]\n",
    "\n",
    "    y_train = labels[train_index]\n",
    "    y_test = labels[test_index]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    EPOCHS = 20\n",
    "    BATCH_SIZE = 128\n",
    "\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(50, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(50, input_dim=X_train.shape[1], activation=tf.nn.swish))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "    (test_loss, test_acc) = model.evaluate(X_test, y_test)\n",
    "    print('Accuracy:', test_acc)\n",
    "    accs.append(test_acc)\n",
    "    \n",
    "    \n",
    "\n",
    "    y_preds = model.predict(X_test)\n",
    "    y_preds = np.where(y_preds < 0.5,0,1)\n",
    "\n",
    "\n",
    "    print(\"accuracy:\", accuracy_score(y_test,y_preds))\n",
    "\n",
    "    cm=confusion_matrix(y_test,y_preds)\n",
    "    cm = pd.DataFrame(cm, index = [i for i in \"01\"],\n",
    "                      columns = [i for i in \"01\"])\n",
    "    cm.index.name = 'Actual'\n",
    "    cm.columns.name = 'Predicted'\n",
    "    sns.heatmap(cm, annot=True, \n",
    "                cmap='Blues', cbar=False)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"============================================\")\n",
    "    fold_no+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
