{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from collections import Counter\n",
    "import time\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "#from keras.utils import to_categorical\n",
    "import feather\n",
    "import random\n",
    "from datetime import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = \"Datasets/final_datasets/merged_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = feather.read_dataframe(f\"{FILENAME}.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove those one-hot encoded columns in the dataset created by Abhi\n",
    "\n",
    "def in_name(c, one_hots):\n",
    "    for col_name in one_hots:\n",
    "        if c.startswith(f\"{col_name}_\"):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "one_hots = ['Wind_Direction', 'Timezone','State', 'Weather_Condition']\n",
    "remove = [col for col in data.columns if in_name(col, one_hots)]\n",
    "df = data.drop(remove, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove missing values\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Severity'] = df['Severity'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean wind direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* \"CALM\" = [\"Calm\", \"CALM\"]\n",
    "* \"W\" = [\"W\", \"West\", \"WSW\", \"WNW\"] \n",
    "* \"S\" = [\"S\", \"South\", \"SSW\", \"SSE\"] \n",
    "* \"N\" = [\"N\", \"North\", \"NNW\", \"NNE\"] \n",
    "* \"E\" = [\"E\", \"East\", \"ESE\", \"ENE\"]\n",
    "* \"VAR\" = [\"VAR\", \"Variable\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Wind_Direction']=='Calm','Wind_Direction'] = 'CALM'\n",
    "df.loc[(df['Wind_Direction']=='West')|(df['Wind_Direction']=='WSW')|(df['Wind_Direction']=='WNW'),'Wind_Direction'] = 'W'\n",
    "df.loc[(df['Wind_Direction']=='South')|(df['Wind_Direction']=='SSW')|(df['Wind_Direction']=='SSE'),'Wind_Direction'] = 'S'\n",
    "df.loc[(df['Wind_Direction']=='North')|(df['Wind_Direction']=='NNW')|(df['Wind_Direction']=='NNE'),'Wind_Direction'] = 'N'\n",
    "df.loc[(df['Wind_Direction']=='East')|(df['Wind_Direction']=='ESE')|(df['Wind_Direction']=='ENE'),'Wind_Direction'] = 'E'\n",
    "df.loc[df['Wind_Direction']=='Variable','Wind_Direction'] = 'VAR'\n",
    "print(\"Wind Direction after simplification: \", df['Wind_Direction'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean weather condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Counter(df['Weather_Condition'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.timeanddate.com/weather/glossary.html <br>\n",
    "\n",
    "**Create features according the different weather conditions** <br>\n",
    "Scattered clouds, partly cloudy = PARTLY CLOUDY <br>\n",
    "Overcast, Mostly cloudly, Cloudy = CLOUDY <br>\n",
    "Fair, Clear = CLEAR <br>\n",
    "Snow (light snow, heavy snow), and wintry mix  = SNOW <br>\n",
    "drizzle, light rain/drizzle, light freezing rain/drizzle = LIGHT RAIN <br>\n",
    "Heavy Rain, heavy thunderstorms, heavy t-storm = HEAVY RAIN <br>\n",
    "Haze, fog, mist, smoke = fog     *(see https://www.worldatlas.com/articles/what-are-the-differences-between-mist-haze-and-fog.html)*<br>\n",
    "Rain, light thunderstorms, thunderstorms, t-storm, thunder = RAIN <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_condition(string):\n",
    "    \n",
    "    conditions = ['Clear', 'Partly Cloudy', 'Cloudy', 'Snow', 'Light Rain', 'Heavy Rain', 'Rain', 'Fog'] \n",
    "    strings = [['clear', 'fair'],\n",
    "              ['partly cloudy', 'scattered clouds'],\n",
    "              ['overcast', 'mostly cloudy', 'cloudy'],\n",
    "              ['snow', 'wintry mix'],\n",
    "              ['drizzle', 'light rain', 'light freezing rain'],\n",
    "              ['heavy rain', 'heavy thunderstorms', 'heavy t-storm'],\n",
    "              ['rain', 'thunderstorms', 't-storm', 'thunder', 'showers'],\n",
    "              ['fog', 'haze', 'mist', 'smoke']]\n",
    "\n",
    "    for j, k in enumerate(strings):\n",
    "        for val in k:\n",
    "            if val in string.lower():\n",
    "                return conditions[j]\n",
    "    return 'Others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in df['Weather_Condition'].values:\n",
    "    res.append(get_condition(i))\n",
    "\n",
    "df['Condition'] = res\n",
    "df[['Condition', 'Weather_Condition']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "conditions = ['Clear', 'Partly Cloudy', 'Cloudy', 'Snow', 'Light Rain', 'Heavy Rain', 'Rain', 'Fog', 'Others'] \n",
    "\n",
    "for i in conditions:\n",
    "    print(i, \":\")\n",
    "    print(set(df[df['Condition']==i]['Weather_Condition']))\n",
    "    print(sum(df['Condition']==i))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "df = df[df['Condition']!='Others']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode ['Wind_Direction', 'Timezone', 'State', 'Condition']\n",
    "\n",
    "one_hots = ['Wind_Direction', 'Timezone','State', 'Condition']\n",
    "oh = pd.DataFrame()\n",
    "for c in one_hots:\n",
    "    dummies = pd.get_dummies(df[c], prefix=c)\n",
    "    oh = pd.concat([oh, dummies], axis=1)\n",
    "\n",
    "df = pd.concat([df, oh], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this dataframe\n",
    "df = df.reset_index(drop = True)\n",
    "df.to_feather(\"{}_v1.feather\".format(FILENAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = feather.read_dataframe(\"{}_v1.feather\".format(FILENAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With numeric attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data\n",
    "#BUM NOEXIT ROUNABOUT GIVEWAY removed due to badly distributed data\n",
    "drop = ['Unnamed: 0', 'ID', 'Start_Lat', 'Start_Lng', 'Start_Time', 'End_Time', 'Weather_Timestamp', 'Description', \n",
    "        'Distance(mi)', \n",
    "        'County', 'City', 'Airport_Code', \n",
    "        'Wind_Direction', 'Timezone', 'State', 'Condition', 'Weather_Condition',\n",
    "        'Street', 'Bump', 'No_Exit', 'Roundabout', 'Give_Way', 'Traffic_Calming',\n",
    "        \"Wind_Direction\"]\n",
    "\n",
    "df = df.drop(drop, axis=1).reset_index(drop=True)\n",
    "\n",
    "# Convert to feather file format\n",
    "df.to_feather(\"{}_numeric_v2.feather\".format(FILENAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### without numeric attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filter the data\n",
    "#BUM NOEXIT ROUNABOUT GIVEWAY removed due to badly distributed data\n",
    "drop = ['Unnamed: 0', 'ID', 'Start_Lat', 'Start_Lng', 'Start_Time', 'End_Time', 'Weather_Timestamp', 'Description', \n",
    "        'Distance(mi)', \n",
    "        'County', 'City', 'Airport_Code', \n",
    "        'Wind_Direction', 'Timezone', 'State', 'Condition', 'Weather_Condition',\n",
    "        'Street', 'Bump', 'No_Exit', 'Roundabout', 'Give_Way', 'Traffic_Calming',\n",
    "       'Temperature(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Direction', 'Wind_Speed(mph)', 'Precipitation(in)',\n",
    "       'Population_County', 'Drive_County', 'Transit_County', 'Walk_County', 'MedianHouseholdIncome_County']\n",
    "\n",
    "df = df.drop(drop, axis=1).reset_index(drop=True)\n",
    "\n",
    "# Convert to feather file format\n",
    "df.to_feather(\"{}_v2.feather\".format(FILENAME))\n",
    "\n",
    "# clears memory allocated to df\n",
    "df = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear memory\n",
    "del(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding best neuron size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = feather.read_dataframe(\"{}_v2.feather\".format(FILENAME))\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# One hot encode labels\n",
    "n = len(data)\n",
    "labels = data['Severity']\n",
    "y = np.zeros((n, 4))\n",
    "for i in range(n):\n",
    "    y[i, labels[i]-1] = 1\n",
    "    \n",
    "X = data.drop('Severity', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30034)\n",
    "\n",
    "max_neurons = X_train.shape[1]\n",
    "neuron_size = range(max_neurons,4,-10)\n",
    "\n",
    "for i in neuron_size:\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(i, activation=tf.nn.swish,input_shape=(X_train.shape[1],)))\n",
    "    model.add(tf.keras.layers.Dense(4, activation=tf.nn.sigmoid))\n",
    "\n",
    "    # Compile and print out summary of model\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    print(\"==================================================\")\n",
    "    print(\"Number of Neurons: \",i)\n",
    "    print(\"==================================================\")\n",
    "    model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "    model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation with numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "data = feather.read_dataframe(\"{}_numeric_v2.feather\".format(FILENAME))\n",
    "labels = data['Severity']\n",
    "X = data.drop('Severity', axis=1)\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, random_state=30034, shuffle=False)\n",
    "\n",
    "fold_no = 1\n",
    "accs = []  # store each accuracy\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X, labels):\n",
    "\n",
    "    # One hot encode labels\n",
    "    print(\"FOLD NUMBER = \", str(fold_no))\n",
    "\n",
    "\n",
    "    X_train = X[train_index]\n",
    "    X_test = X[test_index]\n",
    "    \n",
    "    \n",
    "    y_train = np.zeros((len(X_train), 4))\n",
    "    for i in range(len(X_train)):\n",
    "        y_train[i, labels[i]-1] = 1\n",
    "\n",
    "    y_test = np.zeros((len(X_test), 4))\n",
    "    for i in range(len(X_test)):\n",
    "        y_test[i, labels[i]-1] = 1\n",
    "\n",
    "    EPOCHS = 5\n",
    "    BATCH_SIZE = 128\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(70, activation=tf.nn.swish,input_shape=(X_train.shape[1],)))\n",
    "    model.add(tf.keras.layers.Dense(4, activation=tf.nn.sigmoid))\n",
    "\n",
    "    # Compile and print out summary of model\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "    (test_loss, test_acc) = model.evaluate(X_test, y_test)\n",
    "    print('Accuracy:', test_acc)\n",
    "    accs.append(test_acc)\n",
    "    print(\"============================================\")\n",
    "    fold_no+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation without numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "p = []\n",
    "t = []\n",
    "for i in y_preds:\n",
    "    p.append(np.argmax(i)+1)\n",
    "\n",
    "for i in y_test:\n",
    "    t.append(np.argmax(i)+1)    \n",
    "\n",
    "print(\"accuracy:\", accuracy_score(t, p))\n",
    "\n",
    "cm=confusion_matrix(t,p)\n",
    "cm = pd.DataFrame(cm, index = [i for i in \"1234\"],\n",
    "                  columns = [i for i in \"1234\"])\n",
    "cm.index.name = 'Actual'\n",
    "cm.columns.name = 'Predicted'\n",
    "sns.heatmap(cm, annot=True, \n",
    "            cmap='Blues', cbar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "data = feather.read_dataframe(\"{}_v2.feather\".format(FILENAME))\n",
    "labels = data['Severity']\n",
    "X = data.drop('Severity', axis=1)\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, random_state=30034, shuffle=False)\n",
    "\n",
    "fold_no = 1\n",
    "accs = []  # store each accuracy\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X, labels):\n",
    "\n",
    "    # One hot encode labels\n",
    "    print(\"FOLD NUMBER = \", str(fold_no))\n",
    "\n",
    "\n",
    "    X_train = X[train_index]\n",
    "    X_test = X[test_index]\n",
    "\n",
    "    y_train = np.zeros((len(X_train), 4))\n",
    "    for i in range(len(X_train)):\n",
    "        y_train[i, labels[i]-1] = 1\n",
    "\n",
    "    y_test = np.zeros((len(X_test), 4))\n",
    "    for i in range(len(X_test)):\n",
    "        y_test[i, labels[i]-1] = 1\n",
    "\n",
    "    EPOCHS = 5\n",
    "    BATCH_SIZE = 128\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(70, activation=tf.nn.swish,input_shape=(X_train.shape[1],)))\n",
    "    model.add(tf.keras.layers.Dense(4, activation=tf.nn.sigmoid))\n",
    "\n",
    "    # Compile and print out summary of model\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "    (test_loss, test_acc) = model.evaluate(X_test, y_test)\n",
    "    print('Accuracy:', test_acc)\n",
    "    accs.append(test_acc)\n",
    "    print(\"============================================\")\n",
    "    fold_no+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_sev = []\n",
    "for i in data[\"Severity\"].values:\n",
    "    if i == 1 or i == 2:\n",
    "        grouped_sev.append(0)\n",
    "    else:\n",
    "        grouped_sev.append(1)\n",
    "\n",
    "data[\"Grouped_Severity\"] = grouped_sev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "labels = data['Grouped_Severity']\n",
    "X = data.drop(['Severity',\"Grouped_Severity\"], axis=1)\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, random_state=30034, shuffle=False)\n",
    "\n",
    "fold_no = 1\n",
    "accs = []  # store each accuracy\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X, labels):\n",
    "\n",
    "    # One hot encode labels\n",
    "    print(\"FOLD NUMBER = \", str(fold_no))\n",
    "\n",
    "\n",
    "    X_train = X[train_index]\n",
    "    X_test = X[test_index]\n",
    "\n",
    "    y_train = labels[train_index]\n",
    "    y_test = labels[test_index]\n",
    "\n",
    "    EPOCHS = 10\n",
    "    BATCH_SIZE = 128\n",
    "\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(40, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "    (test_loss, test_acc) = model.evaluate(X_test, y_test)\n",
    "    print('Accuracy:', test_acc)\n",
    "    accs.append(test_acc)\n",
    "    print(\"============================================\")\n",
    "    fold_no+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = feather.read_dataframe(\"{}_numeric_v2.feather\".format(FILENAME))\n",
    "\n",
    "grouped_sev = []\n",
    "for i in data[\"Severity\"].values:\n",
    "    if i == 1 or i == 2:\n",
    "        grouped_sev.append(0)\n",
    "    else:\n",
    "        grouped_sev.append(1)\n",
    "\n",
    "data[\"Grouped_Severity\"] = grouped_sev\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "labels = data['Grouped_Severity']\n",
    "X = data.drop(['Severity',\"Grouped_Severity\"], axis=1)\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, random_state=30034, shuffle=False)\n",
    "\n",
    "fold_no = 1\n",
    "accs = []  # store each accuracy\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X, labels):\n",
    "\n",
    "    # One hot encode labels\n",
    "    print(\"FOLD NUMBER = \", str(fold_no))\n",
    "\n",
    "\n",
    "    X_train = X[train_index]\n",
    "    X_test = X[test_index]\n",
    "\n",
    "    y_train = labels[train_index]\n",
    "    y_test = labels[test_index]\n",
    "\n",
    "    EPOCHS = 10\n",
    "    BATCH_SIZE = 128\n",
    "\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(40, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "    (test_loss, test_acc) = model.evaluate(X_test, y_test)\n",
    "    print('Accuracy:', test_acc)\n",
    "    accs.append(test_acc)\n",
    "    print(\"============================================\")\n",
    "    fold_no+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Temperature(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', \n",
    "        'Wind_Speed(mph)', 'Precipitation(in)',\n",
    "       'Population_County', 'Drive_County', 'Transit_County', 'Walk_County', 'MedianHouseholdIncome_County']\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "f, axes = plt.subplots(6,2, figsize=(15,20))\n",
    "y = 0;\n",
    "for name in cols[1:]:\n",
    "    i, j = divmod(y, 2)\n",
    "    sns.boxplot(x=data[name], ax=axes[i, j])\n",
    "    y = y+1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing one class SVM for outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def outlier_removal(data,columns):\n",
    "    for col in columns:\n",
    "        Q1 = np.quantile(data[col].values,0.25)\n",
    "        Q3 = np.quantile(data[col].values,0.75)\n",
    "        IQR = Q3-Q1\n",
    "        \n",
    "        lower = Q1 - 1.5*IQR\n",
    "        upper = Q3+ 1.5*IQR\n",
    "        \n",
    "        data = data[(data[col]>=lower) & (data[col]<=upper)]\n",
    "    return data\n",
    "\n",
    "\n",
    "data = feather.read_dataframe(\"{}_numeric_v2.feather\".format(FILENAME))\n",
    "\n",
    "numeric_cols = ['Temperature(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', \n",
    "        'Wind_Speed(mph)', 'Precipitation(in)',\n",
    "       'Population_County', 'Drive_County', 'Transit_County', 'Walk_County', 'MedianHouseholdIncome_County']\n",
    "data = outlier_removal(data,numeric_cols).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = ['Temperature(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', \n",
    "        'Wind_Speed(mph)', 'Precipitation(in)',\n",
    "       'Population_County', 'Drive_County', 'Transit_County', 'Walk_County', 'MedianHouseholdIncome_County']\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "f, axes = plt.subplots(6,2, figsize=(15,20))\n",
    "y = 0;\n",
    "for name in cols[1:]:\n",
    "    i, j = divmod(y, 2)\n",
    "    sns.boxplot(x=new_data[name], ax=axes[i, j])\n",
    "    y = y+1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Grouped_Severity'] = np.where(data['Severity']<=2, 0, 1)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "labels = data['Grouped_Severity']\n",
    "X = data.drop(['Severity',\"Grouped_Severity\",'Precipitation(in)','Visibility(mi)'], axis=1)\n",
    "\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, random_state=30034, shuffle=False)\n",
    "\n",
    "fold_no = 1\n",
    "accs = []  # store each accuracy\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X, labels):\n",
    "\n",
    "    # One hot encode labels\n",
    "    print(\"FOLD NUMBER = \", str(fold_no))\n",
    "\n",
    "\n",
    "    X_train = X[train_index]\n",
    "    X_test = X[test_index]\n",
    "\n",
    "    y_train = labels[train_index]\n",
    "    y_test = labels[test_index]\n",
    "\n",
    "    EPOCHS = 20\n",
    "    BATCH_SIZE = 128\n",
    "\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(50, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(50, input_dim=X_train.shape[1], activation=tf.nn.swish))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "    (test_loss, test_acc) = model.evaluate(X_test, y_test)\n",
    "    print('Accuracy:', test_acc)\n",
    "    accs.append(test_acc)\n",
    "    \n",
    "\n",
    "\n",
    "    y_preds = model.predict(X_test)\n",
    "    y_preds = np.where(y_preds < 0.5,0,1)\n",
    "\n",
    "\n",
    "    print(\"accuracy:\", accuracy_score(y_test,y_preds))\n",
    "\n",
    "    cm=confusion_matrix(y_test,y_preds)\n",
    "    cm = pd.DataFrame(cm, index = [i for i in \"01\"],\n",
    "                      columns = [i for i in \"01\"])\n",
    "    cm.index.name = 'Actual'\n",
    "    cm.columns.name = 'Predicted'\n",
    "    sns.heatmap(cm, annot=True, \n",
    "                cmap='Blues', cbar=False)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"============================================\")\n",
    "    fold_no+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
