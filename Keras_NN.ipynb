{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "import feather\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = \"Datasets/Round_2/preproccesed_outliers_1085575_col_11_threshold_09\"\n",
    "data = feather.read_dataframe(\"{}.feather\".format(FILENAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this if you want to use the start latitude and longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create one hot encoding labels\n",
    "n = len(data)\n",
    "labels = data['Severity']\n",
    "labels_oh = np.zeros((n, 4))\n",
    "for i in range(n):\n",
    "    labels_oh[i, labels[i]-1] = 1\n",
    "    \n",
    "# Get the attributes\n",
    "atts_oh = data.drop('Severity', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(atts_oh, labels_oh, test_size=0.33, random_state=30034)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\liyoa\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\liyoa\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\function.py:1007: calling Graph.create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 30)                4410      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 124       \n",
      "=================================================================\n",
      "Total params: 4,534\n",
      "Trainable params: 4,534\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(30, activation=tf.nn.swish,input_shape=(X_train.shape[1],))) # Swish indeed performs better than sigmoid\n",
    "model.add(tf.keras.layers.Dense(4, activation=tf.nn.softmax))\n",
    "\n",
    "# Compile and print out summary of model\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1431510/1431510 [==============================] - 29s 21us/sample - loss: 0.9818 - acc: 0.6927\n",
      "Epoch 2/20\n",
      "1431510/1431510 [==============================] - 30s 21us/sample - loss: 0.6602 - acc: 0.7098\n",
      "Epoch 3/20\n",
      "1431510/1431510 [==============================] - 30s 21us/sample - loss: 0.5656 - acc: 0.7119\n",
      "Epoch 4/20\n",
      "1431510/1431510 [==============================] - 30s 21us/sample - loss: 0.5618 - acc: 0.7127\n",
      "Epoch 5/20\n",
      "1431510/1431510 [==============================] - 31s 21us/sample - loss: 0.5602 - acc: 0.7130\n",
      "Epoch 6/20\n",
      "1431510/1431510 [==============================] - 31s 21us/sample - loss: 0.5587 - acc: 0.7142\n",
      "Epoch 7/20\n",
      "1431510/1431510 [==============================] - 31s 22us/sample - loss: 0.5579 - acc: 0.7146\n",
      "Epoch 8/20\n",
      "1431510/1431510 [==============================] - 31s 22us/sample - loss: 0.5572 - acc: 0.7152\n",
      "Epoch 9/20\n",
      "1431510/1431510 [==============================] - 33s 23us/sample - loss: 0.5569 - acc: 0.7152\n",
      "Epoch 10/20\n",
      "1431510/1431510 [==============================] - 32s 22us/sample - loss: 0.5564 - acc: 0.7152\n",
      "Epoch 11/20\n",
      "1431510/1431510 [==============================] - 31s 22us/sample - loss: 0.5561 - acc: 0.7153\n",
      "Epoch 12/20\n",
      "1431510/1431510 [==============================] - 31s 22us/sample - loss: 0.5559 - acc: 0.7157\n",
      "Epoch 13/20\n",
      "1431510/1431510 [==============================] - 32s 22us/sample - loss: 0.5555 - acc: 0.7162\n",
      "Epoch 14/20\n",
      "1431510/1431510 [==============================] - 32s 22us/sample - loss: 0.5554 - acc: 0.7167\n",
      "Epoch 15/20\n",
      "1431510/1431510 [==============================] - 32s 22us/sample - loss: 0.5551 - acc: 0.7170\n",
      "Epoch 16/20\n",
      "1431510/1431510 [==============================] - 31s 22us/sample - loss: 0.5548 - acc: 0.7171\n",
      "Epoch 17/20\n",
      "1431510/1431510 [==============================] - 31s 22us/sample - loss: 0.5545 - acc: 0.7176\n",
      "Epoch 18/20\n",
      "1431510/1431510 [==============================] - 32s 22us/sample - loss: 0.5543 - acc: 0.7178\n",
      "Epoch 19/20\n",
      "1431510/1431510 [==============================] - 32s 22us/sample - loss: 0.5541 - acc: 0.7180\n",
      "Epoch 20/20\n",
      "1431510/1431510 [==============================] - 31s 22us/sample - loss: 0.5539 - acc: 0.7179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2595b563c50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705073/705073 [==============================] - 18s 26us/sample - loss: 0.5521 - acc: 0.7192\n",
      "\n",
      "test_acc:  0.71916384\n"
     ]
    }
   ],
   "source": [
    "# Testing the model \n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('\\ntest_acc: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove start lat and start long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_data = data.drop(['Start_Lat', 'Start_Lng'], axis=1)\n",
    "\n",
    "# Create one hot encoding labels\n",
    "n = len(new_data)\n",
    "labels = new_data['Severity']\n",
    "labels_oh = np.zeros((n, 4))\n",
    "for i in range(n):\n",
    "    labels_oh[i, labels[i]-1] = 1\n",
    "    \n",
    "# Get the attributes\n",
    "atts_oh = new_data.drop('Severity', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(atts_oh, labels_oh, test_size=0.33, random_state=30034)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\liyoa\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "1431510/1431510 [==============================] - 33s 23us/sample - loss: 0.5841 - acc: 0.7004\n",
      "Epoch 2/20\n",
      "1431510/1431510 [==============================] - 36s 25us/sample - loss: 0.5729 - acc: 0.7032\n",
      "Epoch 3/20\n",
      "1431510/1431510 [==============================] - 38s 26us/sample - loss: 0.5698 - acc: 0.7044\n",
      "Epoch 4/20\n",
      "1431510/1431510 [==============================] - 37s 26us/sample - loss: 0.5677 - acc: 0.7051\n",
      "Epoch 5/20\n",
      "1431510/1431510 [==============================] - 38s 26us/sample - loss: 0.5664 - acc: 0.7057\n",
      "Epoch 6/20\n",
      "1431510/1431510 [==============================] - 39s 27us/sample - loss: 0.5656 - acc: 0.7063\n",
      "Epoch 7/20\n",
      "1431510/1431510 [==============================] - 38s 27us/sample - loss: 0.5652 - acc: 0.7064\n",
      "Epoch 8/20\n",
      "1431510/1431510 [==============================] - 38s 26us/sample - loss: 0.5649 - acc: 0.7069\n",
      "Epoch 9/20\n",
      "1431510/1431510 [==============================] - 42s 29us/sample - loss: 0.5646 - acc: 0.7069\n",
      "Epoch 10/20\n",
      "1431510/1431510 [==============================] - 38s 26us/sample - loss: 0.5644 - acc: 0.7071\n",
      "Epoch 11/20\n",
      "1431510/1431510 [==============================] - 37s 26us/sample - loss: 0.5642 - acc: 0.7072\n",
      "Epoch 12/20\n",
      "1431510/1431510 [==============================] - 37s 26us/sample - loss: 0.5641 - acc: 0.7070\n",
      "Epoch 13/20\n",
      "1431510/1431510 [==============================] - 37s 26us/sample - loss: 0.5641 - acc: 0.7072\n",
      "Epoch 14/20\n",
      "1431510/1431510 [==============================] - 36s 25us/sample - loss: 0.5640 - acc: 0.7072\n",
      "Epoch 15/20\n",
      "1431510/1431510 [==============================] - 38s 26us/sample - loss: 0.5638 - acc: 0.7072s - loss: 0.5638 - acc: \n",
      "Epoch 16/20\n",
      "1431510/1431510 [==============================] - 37s 26us/sample - loss: 0.5637 - acc: 0.7074\n",
      "Epoch 17/20\n",
      "1431510/1431510 [==============================] - 36s 25us/sample - loss: 0.5636 - acc: 0.7074\n",
      "Epoch 18/20\n",
      "1431510/1431510 [==============================] - 39s 27us/sample - loss: 0.5636 - acc: 0.7074\n",
      "Epoch 19/20\n",
      "1431510/1431510 [==============================] - 40s 28us/sample - loss: 0.5635 - acc: 0.7074\n",
      "Epoch 20/20\n",
      "1431510/1431510 [==============================] - 39s 27us/sample - loss: 0.5634 - acc: 0.7072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17de6197d30>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705073/705073 [==============================] - 19s 28us/sample - loss: 0.5671 - acc: 0.6919\n",
      "\n",
      "test_acc:  0.69194824\n"
     ]
    }
   ],
   "source": [
    "# Testing the model \n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('\\ntest_acc: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Just analysing the count of each weather conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blowing Dust 37\n",
      "Blowing Dust / Windy 10\n",
      "Blowing Sand 1\n",
      "Blowing Snow 60\n",
      "Blowing Snow / Windy 0\n",
      "Clear 490250\n",
      "Cloudy 142594\n",
      "Cloudy / Windy 1421\n",
      "Drifting Snow 0\n",
      "Drizzle 351\n",
      "Drizzle / Windy 0\n",
      "Drizzle and Fog 48\n",
      "Dust Whirls 0\n",
      "Fair 406728\n",
      "Fair / Windy 2632\n",
      "Fog 12842\n",
      "Fog / Windy 9\n",
      "Freezing Drizzle 0\n",
      "Freezing Rain 0\n",
      "Freezing Rain / Windy 0\n",
      "Funnel Cloud 12\n",
      "Hail 1\n",
      "Haze 16806\n",
      "Haze / Windy 9\n",
      "Heavy Blowing Snow 0\n",
      "Heavy Drizzle 23\n",
      "Heavy Freezing Drizzle 0\n",
      "Heavy Freezing Rain 0\n",
      "Heavy Ice Pellets 0\n",
      "Heavy Rain 375\n",
      "Heavy Rain / Windy 3\n",
      "Heavy Rain Shower 0\n",
      "Heavy Rain Showers 0\n",
      "Heavy Sleet 0\n",
      "Heavy Smoke 0\n",
      "Heavy Snow 125\n",
      "Heavy Snow / Windy 3\n",
      "Heavy Snow with Thunder 0\n",
      "Heavy T-Storm 146\n",
      "Heavy T-Storm / Windy 0\n",
      "Heavy Thunderstorms and Rain 45\n",
      "Heavy Thunderstorms and Snow 0\n",
      "Heavy Thunderstorms with Small Hail 0\n",
      "Ice Pellets 19\n",
      "Light Blowing Snow 0\n",
      "Light Drizzle 5170\n",
      "Light Drizzle / Windy 6\n",
      "Light Fog 2\n",
      "Light Freezing Drizzle 360\n",
      "Light Freezing Fog 202\n",
      "Light Freezing Rain 378\n",
      "Light Freezing Rain / Windy 0\n",
      "Light Hail 1\n",
      "Light Haze 8\n",
      "Light Ice Pellets 65\n",
      "Light Rain 49849\n",
      "Light Rain / Windy 285\n",
      "Light Rain Shower 20\n",
      "Light Rain Shower / Windy 1\n",
      "Light Rain Showers 14\n",
      "Light Rain with Thunder 757\n",
      "Light Sleet 4\n",
      "Light Snow 14695\n",
      "Light Snow / Windy 38\n",
      "Light Snow and Sleet 3\n",
      "Light Snow and Sleet / Windy 0\n",
      "Light Snow Grains 3\n",
      "Light Snow Shower 2\n",
      "Light Snow Showers 0\n",
      "Light Snow with Thunder 0\n",
      "Light Thunderstorm 2\n",
      "Light Thunderstorms and Rain 1298\n",
      "Light Thunderstorms and Snow 3\n",
      "Low Drifting Snow 3\n",
      "Mist 905\n",
      "Mostly Cloudy 343414\n",
      "Mostly Cloudy / Windy 1638\n",
      "N/A Precipitation 72\n",
      "Overcast 242619\n",
      "Partial Fog 2\n",
      "Partial Fog / Windy 0\n",
      "Partly Cloudy 244808\n",
      "Partly Cloudy / Windy 1053\n",
      "Patches of Fog 1180\n",
      "Patches of Fog / Windy 2\n",
      "Rain 1994\n",
      "Rain / Windy 14\n",
      "Rain and Sleet 2\n",
      "Rain Shower 4\n",
      "Rain Showers 0\n",
      "Sand 0\n",
      "Sand / Dust Whirls Nearby 0\n",
      "Sand / Dust Whirlwinds 19\n",
      "Sand / Dust Whirlwinds / Windy 0\n",
      "Scattered Clouds 139780\n",
      "Shallow Fog 602\n",
      "Showers in the Vicinity 105\n",
      "Sleet 0\n",
      "Small Hail 15\n",
      "Smoke 1841\n",
      "Smoke / Windy 3\n",
      "Snow 723\n",
      "Snow / Windy 0\n",
      "Snow and Sleet 1\n",
      "Snow and Sleet / Windy 0\n",
      "Snow and Thunder 0\n",
      "Snow Grains 1\n",
      "Snow Showers 0\n",
      "Squalls 17\n",
      "Squalls / Windy 5\n",
      "T-Storm 755\n",
      "T-Storm / Windy 11\n",
      "Thunder 1581\n",
      "Thunder / Windy 37\n",
      "Thunder / Wintry Mix / Windy 0\n",
      "Thunder and Hail 0\n",
      "Thunder and Hail / Windy 0\n",
      "Thunder in the Vicinity 2076\n",
      "Thunderstorm 3140\n",
      "Thunderstorms and Rain 126\n",
      "Thunderstorms and Snow 1\n",
      "Tornado 0\n",
      "Volcanic Ash 0\n",
      "Widespread Dust 40\n",
      "Widespread Dust / Windy 1\n",
      "Wintry Mix 276\n",
      "Wintry Mix / Windy 1\n",
      "127\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for col in data.columns:\n",
    "    if col.startswith('Weather_Condition'):\n",
    "        print(col[len('Weather_Condition_'):], sum(data[col]))\n",
    "        count = count+1\n",
    "print(count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
